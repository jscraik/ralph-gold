OpenAI Codex v0.87.0-alpha.1 (research preview)
--------
workdir: /Users/jamiecraik/dev/agent-skills
model: gpt-5.2-codex
provider: openai
approval: never
sandbox: read-only
reasoning effort: medium
reasoning summaries: auto
session id: 019bcd5d-ca76-77d0-b26f-4620f8a65cc8
--------
user
$repoprompt

How do I use rp-cli in automation?

mcp: RepoPrompt starting
mcp: pieces starting
mcp: XcodeBuildMCP starting
mcp: local-memory starting
mcp: openaiDeveloperDocs starting
mcp: RepoPrompt ready
mcp: local-memory ready
mcp: openaiDeveloperDocs ready
mcp: XcodeBuildMCP ready
mcp: pieces ready
mcp startup: ready: RepoPrompt, local-memory, openaiDeveloperDocs, XcodeBuildMCP, pieces

thinking
**Preparing to read skill file**

I plan to read the skill file using a read operation, considering sandbox read-only constraints, and will check relevant documentation to clarify questions about the rp-cli tool.
exec
/bin/zsh -lc ls in /Users/jamiecraik/dev/agent-skills succeeded in 52ms:
README.md
SKILL.md
apple
backend
build
frontend
github
product
scripts
skills
utilities

thinking
**Reading repoprompt skill file**
exec
/bin/zsh -lc 'cat /Users/jamiecraik/dev/agent-skills/product/repoprompt/SKILL.md' in /Users/jamiecraik/dev/agent-skills succeeded in 52ms:
---
name: repoprompt
description: "Plan and guide integration of Repo Prompt (MCP, rp-cli, Compose/Chat/Apply) into AI coding workflows. Use when Codex needs to work with Repo Prompt for: (1) setup/integration, (2) workflow selection, (3) context optimization with codemaps/slices, or (4) comparisons with AI editors."
metadata:
  short-description: Integrate Repo Prompt into workflows
  version: "1.0.0"
  last_updated: "2026-01-17"
---

# Repo Prompt Integration

## Compliance
- Check against GOLD Industry Standards guide in ~/.codex/AGENTS.override.md

## Overview
Guide the user to the most effective Repo Prompt integration path for their workflow, with minimal setup friction and maximal context efficiency.

## When to Use
- User asks how to integrate Repo Prompt with Claude Code, Cursor, Codex, or other editors/agents.
- User asks how to use Compose vs Chat vs Apply/Pro Edit workflows.

thinking
**Checking references file**

I'm opening the references file to find instructions or details about rp-cli usage.
exec
/bin/zsh -lc 'cat /Users/jamiecraik/dev/agent-skills/product/repoprompt/references/repoprompt_source.md' in /Users/jamiecraik/dev/agent-skills succeeded in 52ms:
# Repo Prompt Source Notes (Provided)

Use this as source material for summaries and explanations. Prefer concise paraphrase over long quotes. Avoid inventing pricing or feature availability; use what is here or ask.

## Overview

Repo Prompt helps build token-efficient, context-rich prompts so AI models understand code better. It targets the common problem of too little context (hallucinations) vs too much (token waste). Typical pain points:
- Manual copy/paste of files
- Blind agent discovery that burns tokens
- Paying per-token API costs for discovery

### Solution summary
1) Token-efficient context building
- Full content for active files
- Slices for targeted ranges
- Codemaps for signatures only

2) Use existing AI subscriptions via CLI providers
- Claude MAX / ChatGPT Plus or Pro / Google AI


thinking
**Providing rp-cli automation guidance**

The objective is to outline how to automate tasks using rp-cli with minimal assumptions and without inventing commands. The plan is to briefly explain using rp-cli in exec mode for context building and prompt exporting, piping to the model, and applying edits (e.g., with Apply/Pro Edit for XML). Next, I'll suggest requesting the user's environment and specific automation goals to tailor advice, recommend checking "rp-cli --help" for available options, and mention a basic setup and smoke test. I can also offer a short checklist and validation steps. Should I proceed with creating this structured guidance and request for details?
codex
Objective: explain how to use `rp-cli` for automation and give a minimal, safe workflow you can script.

Plan:
1) Confirm your automation shape (CI, local script, or agent runner).
2) Choose the `rp-cli path` (exec vs interactive vs scripting).
3) Outline the minimal “build context → call model → apply edits” loop.
4) Provide a setup checklist and validation (smoke test).
5) List 2–3 next-step options and a recommendation.

Next step to execute: confirm your automation shape (local script, CI job, or agent runner).

Here’s the minimal, safe automation flow using `rp-cli` (no invented flags):

- Use `rp-cli` in exec or script mode to build context from your repo.
- Export the prompt/context and send it to your model (CLI provider or your own API keys).
- If the model returns XML edits, apply them via Repo Prompt Apply/Pro Edit.
- Keep contexts token-efficient with `codemaps/slices` when repo is large.
- Add a “basic setup and smoke test”: select 2–3 files, build prompt, get a response.

Recommendation (default):
- Use exec mode in a script: build context → call model → apply XML edits.
- This keeps automation linear, auditable, and easy to gate.

Setup checklist and validation:
1) Ensure Repo Prompt app is installed and workspace opens.
2) Verify `rp-cli` is available in PATH (or your script can invoke it).
3) Build a tiny context (2–3 files) and export a prompt.
4) Run a model call and confirm you get a response.
5) If the response includes XML, run Apply/Pro Edit and review diffs.

Options (pick one):
1) Simple local script (recommended): `rp-cli` → model call → Apply/Pro Edit.
2) CI job: `rp-cli` to build prompt, model call in CI, then save XML for manual apply.
3) Agent runner: use `rp-cli` as a context backend for your agent.

Should I use /interview-me to explore this systematically? (yes/no)
tokens used
27,221
